{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d3d2c-8d9e-420b-bf48-b633c3b5cc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q aws-cdk-lib boto3 pandas matplotlib\n",
    "!npm install -g aws-cdk  # Make sure CDK CLI is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6906ed1-ce59-48aa-b62d-5e948688351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "from aws_cdk import (\n",
    "    App,\n",
    "    Stack,\n",
    "    Duration,\n",
    "    aws_s3 as s3,\n",
    "    aws_lambda as lambda_,\n",
    "    aws_lambda_event_sources as lambda_events,\n",
    "    aws_cloudwatch as cloudwatch,\n",
    "    aws_cloudwatch_actions as cw_actions,\n",
    "    aws_sns as sns,\n",
    "    aws_iam as iam,\n",
    "    RemovalPolicy\n",
    ")\n",
    "from constructs import Construct\n",
    "import os\n",
    "\n",
    "class DataQualityPipelineStack(Stack):\n",
    "    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n",
    "        super().__init__(scope, construct_id, **kwargs)\n",
    "        \n",
    "        # Create S3 buckets\n",
    "        self.raw_bucket = s3.Bucket(\n",
    "            self, \"RawDataBucket\",\n",
    "            removal_policy=RemovalPolicy.DESTROY,  # For demonstration - use RETAIN in production\n",
    "            auto_delete_objects=True               # For demonstration - remove in production\n",
    "        )\n",
    "        \n",
    "        self.validated_bucket = s3.Bucket(\n",
    "            self, \"ValidatedDataBucket\",\n",
    "            removal_policy=RemovalPolicy.DESTROY,  # For demonstration - use RETAIN in production\n",
    "            auto_delete_objects=True               # For demonstration - remove in production\n",
    "        )\n",
    "        \n",
    "        # Create SNS topic for alerts\n",
    "        self.alert_topic = sns.Topic(\n",
    "            self, \"QualityAlertsTopic\",\n",
    "            display_name=\"Data Quality Alerts\"\n",
    "        )\n",
    "        \n",
    "        # Create Lambda function for validation\n",
    "        self.validator = lambda_.Function(\n",
    "            self, \"TransactionValidator\",\n",
    "            runtime=lambda_.Runtime.PYTHON_3_9,\n",
    "            handler=\"index.handler\",\n",
    "            code=lambda_.Code.from_inline(self.get_validation_code()),\n",
    "            timeout=Duration.minutes(5),\n",
    "            memory_size=512,\n",
    "            environment={\n",
    "                \"VALIDATED_BUCKET\": self.validated_bucket.bucket_name,\n",
    "                \"ALERT_TOPIC\": self.alert_topic.topic_arn\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Grant Lambda permissions\n",
    "        self.raw_bucket.grant_read(self.validator)\n",
    "        self.validated_bucket.grant_write(self.validator)\n",
    "        self.alert_topic.grant_publish(self.validator)\n",
    "        \n",
    "        # Add CloudWatch permissions to Lambda role\n",
    "        self.validator.add_to_role_policy(\n",
    "            iam.PolicyStatement(\n",
    "                actions=[\"cloudwatch:PutMetricData\"],\n",
    "                resources=[\"*\"]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Add S3 trigger for Lambda\n",
    "        self.validator.add_event_source(\n",
    "            lambda_events.S3EventSource(\n",
    "                self.raw_bucket,\n",
    "                events=[s3.EventType.OBJECT_CREATED],\n",
    "                filters=[s3.NotificationKeyFilter(prefix=\"transactions/\")]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Create CloudWatch dashboard\n",
    "        dashboard = cloudwatch.Dashboard(\n",
    "            self, \"QualityDashboard\",\n",
    "            dashboard_name=\"DataQualityDashboard\"\n",
    "        )\n",
    "        \n",
    "        # Add dashboard widgets\n",
    "        dashboard.add_widgets(\n",
    "            cloudwatch.GraphWidget(\n",
    "                title=\"Overall Quality Score\",\n",
    "                left=[\n",
    "                    cloudwatch.Metric(\n",
    "                        namespace=\"DataQuality\",\n",
    "                        metric_name=\"QualityScore\",\n",
    "                        dimensions_map={\"Dataset\": \"Transactions\"},\n",
    "                        statistic=\"Average\",\n",
    "                        period=Duration.minutes(5)\n",
    "                    )\n",
    "                ],\n",
    "                width=12,\n",
    "                height=6\n",
    "            ),\n",
    "            cloudwatch.GraphWidget(\n",
    "                title=\"Valid Records Percentage\",\n",
    "                left=[\n",
    "                    cloudwatch.Metric(\n",
    "                        namespace=\"DataQuality\",\n",
    "                        metric_name=\"ValidRecords\",\n",
    "                        dimensions_map={\"Dataset\": \"Transactions\"},\n",
    "                        statistic=\"Average\",\n",
    "                        period=Duration.minutes(5)\n",
    "                    )\n",
    "                ],\n",
    "                width=12,\n",
    "                height=6\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        dashboard.add_widgets(\n",
    "            cloudwatch.GraphWidget(\n",
    "                title=\"Error Percentages by Type\",\n",
    "                left=[\n",
    "                    cloudwatch.Metric(\n",
    "                        namespace=\"DataQuality\",\n",
    "                        metric_name=\"missing_customer_id\",\n",
    "                        dimensions_map={\"Dataset\": \"Transactions\"},\n",
    "                        statistic=\"Average\",\n",
    "                        period=Duration.minutes(5)\n",
    "                    ),\n",
    "                    cloudwatch.Metric(\n",
    "                        namespace=\"DataQuality\",\n",
    "                        metric_name=\"negative_amount\",\n",
    "                        dimensions_map={\"Dataset\": \"Transactions\"},\n",
    "                        statistic=\"Average\",\n",
    "                        period=Duration.minutes(5)\n",
    "                    ),\n",
    "                    cloudwatch.Metric(\n",
    "                        namespace=\"DataQuality\",\n",
    "                        metric_name=\"invalid_timestamp\",\n",
    "                        dimensions_map={\"Dataset\": \"Transactions\"},\n",
    "                        statistic=\"Average\",\n",
    "                        period=Duration.minutes(5)\n",
    "                    ),\n",
    "                    cloudwatch.Metric(\n",
    "                        namespace=\"DataQuality\",\n",
    "                        metric_name=\"invalid_payment_method\",\n",
    "                        dimensions_map={\"Dataset\": \"Transactions\"},\n",
    "                        statistic=\"Average\",\n",
    "                        period=Duration.minutes(5)\n",
    "                    )\n",
    "                ],\n",
    "                width=24,\n",
    "                height=6\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Create CloudWatch alarm\n",
    "        quality_alarm = cloudwatch.Alarm(\n",
    "            self, \"QualityScoreAlarm\",\n",
    "            metric=cloudwatch.Metric(\n",
    "                namespace=\"DataQuality\",\n",
    "                metric_name=\"QualityScore\",\n",
    "                dimensions_map={\"Dataset\": \"Transactions\"},\n",
    "                statistic=\"Average\",\n",
    "                period=Duration.minutes(5)\n",
    "            ),\n",
    "            threshold=85,\n",
    "            comparison_operator=cloudwatch.ComparisonOperator.LESS_THAN_THRESHOLD,\n",
    "            evaluation_periods=1,\n",
    "            alarm_description=\"Data quality score below threshold\"\n",
    "        )\n",
    "        \n",
    "        # Connect alarm to SNS topic\n",
    "        quality_alarm.add_alarm_action(\n",
    "            cw_actions.SnsAction(self.alert_topic)\n",
    "        )\n",
    "    \n",
    "    def get_validation_code(self):\n",
    "        \"\"\"Return Python code for Lambda validation function\"\"\"\n",
    "        return \"\"\"\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Initialize clients\n",
    "s3 = boto3.client('s3')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "sns = boto3.client('sns')\n",
    "\n",
    "# Get environment variables\n",
    "validated_bucket = os.environ['VALIDATED_BUCKET']\n",
    "alert_topic = os.environ['ALERT_TOPIC']\n",
    "\n",
    "def handler(event, context):\n",
    "    # Get the S3 object information\n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = event['Records'][0]['s3']['object']['key']\n",
    "    \n",
    "    try:\n",
    "        # Get the object from S3\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        transactions = json.loads(content)\n",
    "        \n",
    "        # Initialize validation results\n",
    "        validation_metrics = {\n",
    "            'missing_customer_id': 0,\n",
    "            'negative_amount': 0,\n",
    "            'invalid_timestamp': 0,\n",
    "            'invalid_payment_method': 0\n",
    "        }\n",
    "        \n",
    "        # Track valid and invalid records\n",
    "        valid_records = []\n",
    "        invalid_records = []\n",
    "        \n",
    "        # Process each transaction\n",
    "        for transaction in transactions:\n",
    "            errors = []\n",
    "            \n",
    "            # Check for required customer_id\n",
    "            if 'customer_id' not in transaction or not transaction['customer_id']:\n",
    "                errors.append('missing_customer_id')\n",
    "                validation_metrics['missing_customer_id'] += 1\n",
    "            \n",
    "            # Check for negative amounts\n",
    "            if 'amount' in transaction and float(transaction['amount']) < 0:\n",
    "                errors.append('negative_amount')\n",
    "                validation_metrics['negative_amount'] += 1\n",
    "            \n",
    "            # Check timestamp format\n",
    "            if 'timestamp' in transaction:\n",
    "                try:\n",
    "                    datetime.datetime.strptime(transaction['timestamp'], '%Y-%m-%d %H:%M:%S')\n",
    "                except ValueError:\n",
    "                    errors.append('invalid_timestamp')\n",
    "                    validation_metrics['invalid_timestamp'] += 1\n",
    "            \n",
    "            # Check payment method is valid\n",
    "            valid_methods = ['CREDIT', 'DEBIT', 'PAYPAL', 'GIFT_CARD']\n",
    "            if 'payment_method' in transaction and transaction['payment_method'] not in valid_methods:\n",
    "                errors.append('invalid_payment_method')\n",
    "                validation_metrics['invalid_payment_method'] += 1\n",
    "            \n",
    "            # Store transaction in appropriate list\n",
    "            if errors:\n",
    "                transaction['validation_errors'] = errors\n",
    "                invalid_records.append(transaction)\n",
    "            else:\n",
    "                valid_records.append(transaction)\n",
    "        \n",
    "        # Calculate total and passing percentages\n",
    "        total_records = len(transactions)\n",
    "        valid_percentage = (len(valid_records) / total_records) * 100 if total_records > 0 else 0\n",
    "        \n",
    "        # Log validation results\n",
    "        print(f\"Processed {total_records} records\")\n",
    "        print(f\"Valid: {len(valid_records)} ({valid_percentage:.2f}%)\")\n",
    "        print(f\"Invalid: {len(invalid_records)} ({100-valid_percentage:.2f}%)\")\n",
    "        \n",
    "        # Publish metrics to CloudWatch\n",
    "        metric_data = []\n",
    "        \n",
    "        # Overall metrics\n",
    "        metric_data.append({\n",
    "            'MetricName': 'ValidRecords',\n",
    "            'Value': valid_percentage,\n",
    "            'Unit': 'Percent',\n",
    "            'Dimensions': [{'Name': 'Dataset', 'Value': 'Transactions'}]\n",
    "        })\n",
    "        \n",
    "        # Error type metrics\n",
    "        for error_type, count in validation_metrics.items():\n",
    "            error_pct = (count / total_records) * 100 if total_records > 0 else 0\n",
    "            metric_data.append({\n",
    "                'MetricName': error_type,\n",
    "                'Value': error_pct,\n",
    "                'Unit': 'Percent',\n",
    "                'Dimensions': [{'Name': 'Dataset', 'Value': 'Transactions'}]\n",
    "            })\n",
    "        \n",
    "        # Calculate quality score (100 - average error percentage)\n",
    "        error_types = len(validation_metrics)\n",
    "        if error_types > 0 and total_records > 0:\n",
    "            quality_score = 100 - sum([\n",
    "                (validation_metrics[m] / total_records) * 100 \n",
    "                for m in validation_metrics\n",
    "            ]) / error_types\n",
    "        else:\n",
    "            quality_score = 100\n",
    "        \n",
    "        metric_data.append({\n",
    "            'MetricName': 'QualityScore',\n",
    "            'Value': quality_score,\n",
    "            'Unit': 'None',\n",
    "            'Dimensions': [{'Name': 'Dataset', 'Value': 'Transactions'}]\n",
    "        })\n",
    "        \n",
    "        cloudwatch.put_metric_data(\n",
    "            Namespace='DataQuality',\n",
    "            MetricData=metric_data\n",
    "        )\n",
    "        \n",
    "        # Save validated and invalid records\n",
    "        if valid_records:\n",
    "            output_key = key.replace('transactions/', 'validated/')\n",
    "            s3.put_object(\n",
    "                Bucket=validated_bucket,\n",
    "                Key=output_key,\n",
    "                Body=json.dumps(valid_records)\n",
    "            )\n",
    "            print(f\"Saved {len(valid_records)} valid records to validated bucket\")\n",
    "        \n",
    "        if invalid_records:\n",
    "            error_key = key.replace('transactions/', 'errors/')\n",
    "            s3.put_object(\n",
    "                Bucket=validated_bucket,\n",
    "                Key=error_key,\n",
    "                Body=json.dumps(invalid_records)\n",
    "            )\n",
    "            print(f\"Saved {len(invalid_records)} invalid records to error folder\")\n",
    "        \n",
    "        # Alert if quality is poor\n",
    "        if quality_score < 85:\n",
    "            sns.publish(\n",
    "                TopicArn=alert_topic,\n",
    "                Subject=f\"Low data quality score: {quality_score:.2f}\",\n",
    "                Message=json.dumps({\n",
    "                    'quality_score': quality_score,\n",
    "                    'file': f\"s3://{bucket}/{key}\",\n",
    "                    'validation_metrics': validation_metrics,\n",
    "                    'timestamp': datetime.datetime.now().isoformat()\n",
    "                })\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps({\n",
    "                'quality_score': quality_score,\n",
    "                'valid_records': len(valid_records),\n",
    "                'invalid_records': len(invalid_records)\n",
    "            })\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {str(e)}\")\n",
    "        sns.publish(\n",
    "            TopicArn=alert_topic,\n",
    "            Subject=\"Error in data validation\",\n",
    "            Message=f\"Error processing s3://{bucket}/{key}: {str(e)}\"\n",
    "        )\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps({\n",
    "                'error': str(e)\n",
    "            })\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "# Create the CDK app\n",
    "app = App()\n",
    "DataQualityPipelineStack(app, \"DataQualityPipeline\")\n",
    "app.synth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f4b34-c5e1-4cc8-ae47-9fbf82565374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the CDK stack\n",
    "!cdk deploy --require-approval never\n",
    "\n",
    "# Store bucket names for later use\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "cloudformation = boto3.client('cloudformation')\n",
    "response = cloudformation.describe_stacks(StackName='DataQualityPipeline')\n",
    "outputs = {output['OutputKey']: output['OutputValue'] for output in response['Stacks'][0]['Outputs']}\n",
    "\n",
    "# Save the bucket names to environment variables\n",
    "import os\n",
    "os.environ['RAW_BUCKET'] = outputs['RawDataBucket']\n",
    "os.environ['VALIDATED_BUCKET'] = outputs['ValidatedDataBucket']\n",
    "\n",
    "print(f\"Raw data bucket: {os.environ['RAW_BUCKET']}\")\n",
    "print(f\"Validated data bucket: {os.environ['VALIDATED_BUCKET']}\")\n",
    "print(f\"CloudWatch dashboard: {outputs['QualityDashboardURL']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e51916-82f9-4494-a5c1-7d82fd419c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample transaction data with quality issues\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import boto3\n",
    "\n",
    "# Generate synthetic transactions\n",
    "def generate_sample_data(count=100):\n",
    "    transactions = []\n",
    "    for i in range(count):\n",
    "        # Insert occasional errors\n",
    "        has_customer_id = random.random() > 0.05\n",
    "        has_valid_amount = random.random() > 0.08\n",
    "        has_valid_timestamp = random.random() > 0.07\n",
    "        has_valid_method = random.random() > 0.06\n",
    "        \n",
    "        transaction = {\n",
    "            \"transaction_id\": f\"TXN-{i:06d}\",\n",
    "            \"amount\": random.randint(1, 1000) if has_valid_amount else -random.randint(1, 100)\n",
    "        }\n",
    "        \n",
    "        if has_customer_id:\n",
    "            transaction[\"customer_id\"] = f\"CUST-{random.randint(1000, 9999)}\"\n",
    "        \n",
    "        if has_valid_timestamp:\n",
    "            date = datetime.now() - timedelta(days=random.randint(0, 30))\n",
    "            transaction[\"timestamp\"] = date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            transaction[\"timestamp\"] = \"invalid-date\"\n",
    "        \n",
    "        if has_valid_method:\n",
    "            transaction[\"payment_method\"] = random.choice(['CREDIT', 'DEBIT', 'PAYPAL', 'GIFT_CARD'])\n",
    "        else:\n",
    "            transaction[\"payment_method\"] = f\"UNKNOWN-{random.randint(1, 100)}\"\n",
    "        \n",
    "        transactions.append(transaction)\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "# Generate and upload data\n",
    "transactions = generate_sample_data(200)\n",
    "s3 = boto3.client('s3')\n",
    "s3.put_object(\n",
    "    Bucket=os.environ['RAW_BUCKET'],\n",
    "    Key='transactions/sample_batch.json',\n",
    "    Body=json.dumps(transactions)\n",
    ")\n",
    "\n",
    "print(f\"Uploaded 200 sample transactions to s3://{os.environ['RAW_BUCKET']}/transactions/sample_batch.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1dd29-0fa1-4080-9b68-d3e754bb2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait a moment for Lambda to process the file\n",
    "import time\n",
    "print(\"Waiting for Lambda function to process data...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Check Lambda logs\n",
    "import boto3\n",
    "logs = boto3.client('logs')\n",
    "\n",
    "# Get the Lambda function name\n",
    "lambda_client = boto3.client('lambda')\n",
    "functions = lambda_client.list_functions()\n",
    "validator_function = next(f for f in functions['Functions'] if 'TransactionValidator' in f['FunctionName'])\n",
    "function_name = validator_function['FunctionName']\n",
    "\n",
    "# Get log group name\n",
    "log_group_name = f\"/aws/lambda/{function_name}\"\n",
    "\n",
    "# Get log streams\n",
    "log_streams = logs.describe_log_streams(\n",
    "    logGroupName=log_group_name,\n",
    "    orderBy='LastEventTime',\n",
    "    descending=True,\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "if log_streams['logStreams']:\n",
    "    stream_name = log_streams['logStreams'][0]['logStreamName']\n",
    "    \n",
    "    # Get log events\n",
    "    log_events = logs.get_log_events(\n",
    "        logGroupName=log_group_name,\n",
    "        logStreamName=stream_name,\n",
    "        limit=30\n",
    "    )\n",
    "    \n",
    "    print(f\"Recent logs from {function_name}:\")\n",
    "    for event in log_events['events']:\n",
    "        print(event['message'])\n",
    "else:\n",
    "    print(f\"No log streams found for {function_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095740d-c670-45d7-90b4-817a6cf84f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for validated and error records in the output bucket\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List objects in the validated folder\n",
    "try:\n",
    "    validated_objects = s3.list_objects_v2(\n",
    "        Bucket=os.environ['VALIDATED_BUCKET'],\n",
    "        Prefix='validated/'\n",
    "    )\n",
    "    \n",
    "    if 'Contents' in validated_objects:\n",
    "        # Get the first validated file\n",
    "        validated_key = validated_objects['Contents'][0]['Key']\n",
    "        response = s3.get_object(Bucket=os.environ['VALIDATED_BUCKET'], Key=validated_key)\n",
    "        validated_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "        \n",
    "        print(f\"Found {len(validated_data)} valid records\")\n",
    "        print(\"\\nSample valid record:\")\n",
    "        print(json.dumps(validated_data[0], indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error checking validated data: {str(e)}\")\n",
    "\n",
    "# List objects in the errors folder\n",
    "try:\n",
    "    error_objects = s3.list_objects_v2(\n",
    "        Bucket=os.environ['VALIDATED_BUCKET'],\n",
    "        Prefix='errors/'\n",
    "    )\n",
    "    \n",
    "    if 'Contents' in error_objects:\n",
    "        # Get the first error file\n",
    "        error_key = error_objects['Contents'][0]['Key']\n",
    "        response = s3.get_object(Bucket=os.environ['VALIDATED_BUCKET'], Key=error_key)\n",
    "        error_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "        \n",
    "        print(f\"\\nFound {len(error_data)} invalid records\")\n",
    "        print(\"\\nSample invalid record with errors:\")\n",
    "        print(json.dumps(error_data[0], indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error checking error data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8d165-1985-43a3-bc6b-ecde41e00ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch CloudWatch metrics for visualization\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Get metrics for the last hour\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(hours=1)\n",
    "\n",
    "# Get quality score\n",
    "quality_score = cloudwatch.get_metric_data(\n",
    "    MetricDataQueries=[\n",
    "        {\n",
    "            'Id': 'quality',\n",
    "            'MetricStat': {\n",
    "                'Metric': {\n",
    "                    'Namespace': 'DataQuality',\n",
    "                    'MetricName': 'QualityScore',\n",
    "                    'Dimensions': [\n",
    "                        {\n",
    "                            'Name': 'Dataset',\n",
    "                            'Value': 'Transactions'\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                'Period': 300,\n",
    "                'Stat': 'Average'\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    StartTime=start_time,\n",
    "    EndTime=end_time\n",
    ")\n",
    "\n",
    "# Get error metrics\n",
    "error_metrics = cloudwatch.get_metric_data(\n",
    "    MetricDataQueries=[\n",
    "        {\n",
    "            'Id': 'missing_id',\n",
    "            'MetricStat': {\n",
    "                'Metric': {\n",
    "                    'Namespace': 'DataQuality',\n",
    "                    'MetricName': 'missing_customer_id',\n",
    "                    'Dimensions': [\n",
    "                        {\n",
    "                            'Name': 'Dataset',\n",
    "                            'Value': 'Transactions'\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                'Period': 300,\n",
    "                'Stat': 'Average'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Id': 'negative_amount',\n",
    "            'MetricStat': {\n",
    "                'Metric': {\n",
    "                    'Namespace': 'DataQuality',\n",
    "                    'MetricName': 'negative_amount',\n",
    "                    'Dimensions': [\n",
    "                        {\n",
    "                            'Name': 'Dataset',\n",
    "                            'Value': 'Transactions'\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                'Period': 300,\n",
    "                'Stat': 'Average'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Id': 'invalid_timestamp',\n",
    "            'MetricStat': {\n",
    "                'Metric': {\n",
    "                    'Namespace': 'DataQuality',\n",
    "                    'MetricName': 'invalid_timestamp',\n",
    "                    'Dimensions': [\n",
    "                        {\n",
    "                            'Name': 'Dataset',\n",
    "                            'Value': 'Transactions'\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                'Period': 300,\n",
    "                'Stat': 'Average'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Id': 'invalid_payment',\n",
    "            'MetricStat': {\n",
    "                'Metric': {\n",
    "                    'Namespace': 'DataQuality',\n",
    "                    'MetricName': 'invalid_payment_method',\n",
    "                    'Dimensions': [\n",
    "                        {\n",
    "                            'Name': 'Dataset',\n",
    "                            'Value': 'Transactions'\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                'Period': 300,\n",
    "                'Stat': 'Average'\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    StartTime=start_time,\n",
    "    EndTime=end_time\n",
    ")\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot quality score if data exists\n",
    "if quality_score['MetricDataResults'][0]['Values']:\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title('Data Quality Score')\n",
    "    plt.plot(\n",
    "        quality_score['MetricDataResults'][0]['Timestamps'],\n",
    "        quality_score['MetricDataResults'][0]['Values'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        linewidth=2\n",
    "    )\n",
    "    plt.axhline(y=85, color='r', linestyle='--', label='Threshold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Quality Score')\n",
    "\n",
    "# Plot error metrics if data exists\n",
    "if any(result['Values'] for result in error_metrics['MetricDataResults']):\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title('Error Percentages by Type')\n",
    "    \n",
    "    # Only plot if there are values\n",
    "    for result in error_metrics['MetricDataResults']:\n",
    "        if result['Values']:\n",
    "            plt.plot(\n",
    "                result['Timestamps'],\n",
    "                result['Values'],\n",
    "                marker='o',\n",
    "                linestyle='-',\n",
    "                label=result['Id']\n",
    "            )\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Error Percentage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"To view the complete dashboard in AWS Console:\")\n",
    "print(\"1. Navigate to CloudWatch service in AWS Console\")\n",
    "print(\"2. Select 'Dashboards' from the left navigation panel\")\n",
    "print(\"3. Click on 'DataQualityDashboard'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ec972-19ce-4e90-8390-cdd0022bb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destroy the CDK stack to clean up resources\n",
    "# Uncomment and run this cell when you're done\n",
    "\n",
    "# print(\"Cleaning up resources...\")\n",
    "# !cdk destroy --force"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
